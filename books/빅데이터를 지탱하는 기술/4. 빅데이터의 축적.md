# 4. 빅데이터의 축적

> **※ 본 장 출처**  
> - 4-1~4-2: https://boleesystem.tistory.com/1031 (데브아티스트 : 보리의 개발기록)  
> - 4-3~4-5: https://jinyshin.notion.site/8-14a4cff7232680c1b8e9d05fcc9970a8 (8회차 스터디 내용 준비)

---

## 4-1 벌크 형과 스트리밍 형의 데이터 수집

**데이터 수집**: 수집한 데이터를 분산 스토리지에 저장하는 프로세스. 이 과정에서 동종의 데이터를 만들어 처리 가능하게 한다.

### 1) 객체 스토리지와 데이터 수집 — 분산 스토리지에 데이터 읽어들이기

- **빅데이터는 확장성이 큰 '분산 스토리지'에 저장**된다. 분산형 DB를 쓰는 경우도 있지만, 대량 파일 저장에는 **객체 스토리지**를 많이 쓴다. (예: Hadoop의 HDFS, 클라우드의 Amazon S3)
- **객체 스토리지**
  - 여러 컴퓨터·디스크에 파일을 복제해 **중복화·부하 분산**을 구현한다.
  - 일부 하드웨어 장애가 나도 데이터 손실을 줄일 수 있고, 읽기/쓰기를 여러 하드웨어에 나누어 데이터가 늘어나도 성능이 크게 떨어지지 않도록 할 수 있다.
  - **소량 데이터**일 때는 통신 오버헤드가 상대적으로 커서 비효율적일 수 있으므로 주의한다.
- **데이터 수집 시 유의점**
  - 데이터를 수시로 객체 스토리지에 쓰면 **작은 파일이 많이** 생겨 시간이 지날수록 성능 저하 요인이 된다. 작은 데이터는 **어느 정도 모아서 하나의 큰 파일**로 만드는 것이 효율적이다.
  - 반대로 **파일이 지나치게 크면** 네트워크 전송 시간과 예기치 못한 오류 가능성이 늘어난다. **적정 크기**를 유지하는 것이 중요하다.

### 2) 벌크 형의 데이터 전송 — ETL 서버의 설치 필요성

- **벌크형**: 전통적인 데이터 웨어하우스에서 쓰는 방식. DB, 파일 서버, 웹 서비스 등에서 각각의 방식(SQL, API 등)으로 데이터를 추출한다.
- **데이터가 처음부터 분산 스토리지에 있는 것이 아니면**, 데이터 전송을 위한 **ETL 서버**를 둔다.
  - ETL 서버에서는 DW용 ETL 도구, 오픈소스 벌크 전송 도구, 또는 직접 만든 스크립트로 데이터를 전송한다.
- **파일 크기 적정화**
  - ETL 프로세스를 **정기 실행**해 그동안 쌓인 데이터를 한 번에 모아 전송하거나, 전송 단위를 나누어 **적정 크기**로 보낸다.
  - **워크플로 관리 도구**로 태스크 실행을 관리하고, 데이터량이 많을 때는 한 달/하루 단위로 잘게 나누어 한 번의 태스크가 너무 커지지 않도록 조정한다.
- **신뢰성**: 문제가 생겼을 때 **재실행**이 가능한 벌크형 도구를 쓰고, **워크플로 관리 도구**와 조합해 정기 스케줄·오류 통지 등을 맡긴다.

### 3) 스트리밍 형의 데이터 전송 — 계속 전달되는 작은 데이터 취급

- **메시지 배송**: 다수의 클라이언트에서 **끊임없이 작은 데이터**가 오는 방식. 데이터량에 비해 통신 오버헤드가 커서, 이를 처리할 **고성능 서버**가 필요하다.
- **수신 메시지 저장 방식**
  - 작은 데이터 쓰기에 맞는 **NoSQL DB** 사용 (Hive 등 쿼리 엔진으로 조회 가능).
  - 또는 **분산 스토리지에 직접 쓰지 않고**, **메시지 큐/브로커** 같은 중계 시스템에 보낸 뒤, 일정 간격으로 꺼내 **모아서** 분산 스토리지에 저장하는 방식.

**대상별 메시지 배송**

| 대상 | 방식·도구 | 비고 |
|------|-----------|------|
| **웹 브라우저** | 웹 서버에서 메시지 생성·배송. 서버에 데이터를 모았다가 한꺼번에 보내는 경우 많음 (Fluentd, Logstash 등). **웹 이벤트 트래킹**: JS로 브라우저에서 직접 전송, HTML에 태그만 넣으면 됨. | 수집 데이터는 다른 서버로 전달되거나 API 경유로 분산 스토리지에 저장해 다른 데이터와 결합 분석 가능. |
| **모바일 앱** | ① 자체 서버 또는 **MBaaS**. ② 모바일 액세스 분석 서비스 + **SDK**로 이벤트 수집. 오프라인 시 SDK 내부에 쌓았다가 온라인 되면 한꺼번에 전송. | SDK 도입 시 **데이터 중복** 대책 필요. |
| **디바이스(IoT)** | **MQTT**(MQ Telemetry Transport): TCP/IP 기반, **Pub/Sub** 구조. **토픽**(대화방처럼 메시지 송수신 단위)을 두고, 구독자에게 전달. **MQTT 브로커**가 중계. | 네트워크 단절 시 나중에 재전송하는 구조가 **프로토콜 수준**에 포함됨 (HTTP는 앱에서 구현해야 함). |

---

## 4-2 [성능×신뢰성] 메시지 배송의 트레이드 오프

스트리밍 형 데이터 전송인 **메시지 배송**은 성능을 우선하면 **신뢰성**을 희생하는 설계가 많다.

### 1) 메시지 브로커 — 스토리지 성능 문제를 완화하는 중간층

- **메시지 브로커**: 데이터를 **일시적으로 축적**하는 중간층. (예: Apache Kafka, Amazon Kinesis)
- **푸시형·풀형**: 쓰기 속도를 조절하고 파일 크기를 적정화하기 위해 **푸시형 → 풀형**으로 타이밍을 바꾼다.
  - **푸시(push)형**: 송신 측이 데이터를 보냄. **프로듀서(producer)** = 메시지 브로커에 데이터를 넣는 쪽.
  - **풀(pull)형**: 수신 측이 데이터를 가져감. **컨슈머(consumer)** = 꺼내 오는 쪽.  
  메시지 브로커에 쓰기를 모으고, 일정 주기로 꺼낸 데이터를 분산 스토리지에 기록해 스토리지 부하를 피할 수 있다.
- **메시지 라우팅**: 브로커에 쓴 데이터를 **여러 컨슈머**가 읽을 수 있어, 메시지가 복제되고 **여러 경로로 분기**할 수 있다. **스트림 처리**는 짧은 간격으로 차례대로 꺼내 처리하는 방식이다.

### 2) 메시지 배송을 확실히 하는 것은 어렵다 — 신뢰성과 세 가지 설계

다음 중 **하나**를 보장하도록 설계하는 것이 일반적이다.

| 보장 방식 | 의미 | 비고 |
|-----------|------|------|
| **at most once** | 메시지는 최대 한 번 전달. 전송 실패 시 **결손** 가능. | 보통은 결손을 피하려고 재전송을 쓰므로, 실제로는 at least once가 많음. |
| **exactly once** | 손실·중복 없이 정확히 한 번 전달. | 분산 환경에서 두 노드 사이를 보장하려면 **코디네이터**가 필요한데, ① 코디네이터가 항상 있다고 가정하기 어렵고 ② 성능상 판단만 코디네이터에 맡기면 지연이 커진다. 그래서 메시지 배송 시스템에서는 코디네이터를 두지 않고 **at least once**로 가져가며, **중복은 애플리케이션에서 제거**하는 방식이 일반적이다. |
| **at least once** | 메시지는 **반드시 전달** (중복 가능). | **중복 제거**를 해두면 겉으로는 중복이 없는 것처럼 보이게 할 수 있다. 대부분의 메시지 배송 시스템은 at least once를 보장하고, **중복 제거는 이용자(애플리케이션) 책임**이다. TCP/IP처럼 자동으로 중복을 제거해 주지 않는다. |

### 3) 중복 제거는 비용이 큰 오퍼레이션

- **오프셋 기반 중복 제거**: 각 메시지에 오프셋(시작 위치)을 붙인다. **벌크형**처럼 데이터 양이 정해진 경우에 잘 맞는다.
- **고유 ID 기반 중복 제거**: UUID 등 **고유 ID**를 부여한다. 현실적으로는 “최근 받은 ID만 기억해 두고, 그보다 늦게 도착한 중복은 허용”하는 식으로 완화해서 쓴다.
- **End-to-End 신뢰성**: 빅데이터 메시지 배송에서는 **효율**을 우선해, 중간 구간은 at least once만 보장하고 **중간에서 중복 제거는 하지 않는** 구현이 많다. 신뢰성을 높이려면 경로 전체를 at least once로 맞추고, **클라이언트에서 모든 메시지에 고유 ID**를 넣은 뒤 **경로 말단**에서 중복 제거를 수행하는 방식이 필요하다.

### 4) 데이터 수집 파이프라인 — 장기 분석에 맞는 스토리지

- **데이터 수집 파이프라인**: 데이터를 구조화하고 **열 지향 스토리지**로 변환해, **장기 데이터 분석**에 쓸 수 있는 스토리지로 만드는 과정이다.
- **중복을 전제한 설계**: 스트리밍 메시지 배송에서는 중간에 **명시적으로 중복 제거**를 넣지 않는 한 항상 중복 가능성이 있다. 매우 높은 처리량이 필요해 **아주 작은 중복은 허용**하는 경우가 많다.
- **신뢰성이 더 중요할 때**: 스트리밍형 메시지 배송을 **피하고**, 벌크형 등 다른 수집 방식을 쓰는 것이 안전하다.

---

## 4-3 시계열 데이터의 최적화

> **※ 아래 4-3 절 내용은 다음 출처를 바탕으로 정리하였습니다. 출처: https://jinyshin.notion.site/8-14a4cff7232680c1b8e9d05fcc9970a8 (8회차 스터디 내용 준비)**

스트리밍형 메시지 배송에서는 **메시지 도착까지의 시간 지연**이 문제다. 늦게 도착하는 데이터가 집계 속도에 미치는 영향과, **이벤트 시간**을 고려한 **조건절 푸시다운** 등 스토리지 최적화를 다룬다.

### 프로세스 시간과 이벤트 시간

- **이벤트 시간(event time)**: 클라이언트에서 메시지가 **생성된** 시간.
- **프로세스 시간(process time)**: 서버가 **처리한** 시간.
- 데이터 분석의 대상은 주로 **이벤트 시간**이므로, 두 시간의 차이가 문제를 일으킨다. (예: 스마트폰 데이터는 배터리 방전·전파 간섭 등으로 며칠 늦게 도착할 수 있음.)

### 프로세스 시간에 의한 분할과 문제점

- 분산 스토리지에 넣을 때는 보통 **이벤트 시간이 아니라 프로세스 시간**으로 분할한다.
- 과거 특정일(예: 1월 1일) 이벤트를 집계하려면, 그 **이후에 만들어진 모든 파일**에 그날 이벤트가 섞여 있을 수 있다. → 한 달 뒤(2월 1일)에 지금까지 만든 **모든 파일**을 열어 1월 1일 데이터만 꺼내야 비교적 정확한 결과를 얻을 수 있다.
- **문제**: 한 달치 수십만 파일 중 특정일 데이터만 찾는 것은 **시간·자원 낭비**가 크다. 데이터가 이벤트 시간으로 정렬되어 있지 않아 **전체를 로드**해야 원하는 이벤트 시간 포함 여부를 알 수 있기 때문이다.
- **풀 스캔(full scan)**: 다수 파일을 모두 검색하는 쿼리. 시스템 부하를 크게 올리는 원인이다.

### 시계열 인덱스 — 이벤트 시간에 의한 집계 효율화

- **이벤트 시간으로 정렬·인덱싱**하면 효율이 좋아진다. RDB에서 인덱스를 만드는 것과 같은 발상이다.
- **Cassandra** 같은 **시계열 인덱스**를 지원하는 분산 DB를 쓰면, 처음부터 이벤트 시간으로 인덱스된 테이블을 만들 수 있다.
- **장점**: 특정 짧은 시간 범위에 맞춘 집계를 빠르게 실행할 수 있다. 정해진 시간의 이벤트 조사, 실시간 대시보드에 유용.
- **단점**: **장기간·대량** 데이터 집계에는 분산 DB가 비효율적이다. 장기 분석에는 **열 지향 스토리지**를 지속적으로 만드는 구성이 필요하다.

### 조건절 푸시다운 — 이벤트 시간에 의한 집계 효율화

- **매일 한 번** 새로 도착한 데이터를 **배치 처리**로 열 지향 스토리지에 넣는 경우를 생각하자.
- 열 지향 스토리지는 RDB처럼 임의 인덱스를 만들 수는 없지만, **저장 시 데이터를 정렬**해 둘 수 있다. **이벤트 시간으로 정렬**한 뒤 열 지향 스토리지로 변환한다.
- 열 지향 스토리지는 **컬럼 단위 통계**(예: 최솟값·최댓값)를 메타 정보로 갖고 있어, **어떤 파일의 어떤 구간**에 원하는 데이터가 있는지 알 수 있다.
- **조건절 푸시다운(predicate pushdown)**: 이 통계를 이용해 **필요한 최소한의 데이터만 읽도록** 하는 최적화. 이벤트 시간으로 미리 정렬해 두면 조건절 푸시다운이 잘 작동해 **풀 스캔을 피할 수 있다**.

### 이벤트 시간에 의한 분할 — 테이블 파티셔닝, 시계열 테이블

- **시계열 테이블**: 시간으로 분할된 **테이블 파티셔닝** 중, **이벤트 발생 시간**을 파티션 이름에 넣는 방식. (예: 1월 1일 이벤트 → `event_0101` 파티션에 추가. 도착 시점과 무관.)
- **주의**: 새로 도착한 데이터를 매번 새 파일로 만들면, **과거 이벤트 시간**을 가진 데이터가 나중에 들어올 수 있어(몇 년 뒤까지 가능) **각 파티션에 조금씩 계속 추가**된다. 그 결과 **작은 파일이 많이** 생기고 쿼리 성능이 나빠진다.
- 대응: 이벤트 시간 기반 시계열 테이블을 쓸 때는 **작은 데이터를 효율적으로 추가할 수 있는 분산 DB**를 쓰거나, **너무 오래된 데이터는 버리는** 전략이 필요하다.

### 데이터 마트만 이벤트 시간으로 정렬하기

- **권장**: **데이터 수집 단계**에서는 이벤트 시간을 쓰지 않고 **프로세스 시간만**으로 저장한다. **데이터 마트를 만드는 단계**에서만 이벤트 시간으로 정렬한다.
- 그러면 파일이 조각나지 않고, **항상 최적 형태의 데이터 마트**를 유지할 수 있다.

---

## 4-4 비구조화 데이터의 분산 스토리지

> **※ 아래 4-4 절 내용은 다음 출처를 바탕으로 정리하였습니다. 출처: https://jinyshin.notion.site/8-14a4cff7232680c1b8e9d05fcc9970a8 (8회차 스터디 내용 준비)**

NoSQL DB를 쓰면 데이터를 모아 저장할 뿐 아니라 **애플리케이션에서 온라인 조회·실시간 집계**도 할 수 있다. 다만 고도의 집계 기능이 부족한 경우가 많아 **쿼리 엔진과 결합**해 데이터 분석을 하는 형태가 일반적이다.

### [기본 전략] NoSQL DB에 의한 데이터 활용

- 빅데이터용 분산 스토리지에는 **확장성**과 **스키마 없이 저장할 수 있는 유연성**이 요구된다.
- **객체 스토리지**(HDFS, S3 등)는 임의 파일 저장에 유리하지만 단점도 있다.

**객체 스토리지의 단점**

- 파일을 **통째로 교체**하는 방식만 가능해, 수시로 갱신하는 DB 용도에는 맞지 않는다. → 쓰기 빈도가 높은 데이터는 **별도 RDB**에 두고 정기 스냅샷을 하거나 **분산 DB**에 저장한다.
- **중요 데이터**는 트랜잭션 처리가 가능한 DB에 기록하는 것이 원칙이다. 스트리밍 메시지 배송은 트랜잭션이 없어 확실한 기록 보장이 어렵다.
- 객체 스토리지에 넣은 데이터가 **집계 가능한 형태**가 되기까지 **시간이 걸린다**. 열 지향 스토리지 작성에 시간이 필요하다. **기록 직후 활용**이 필요하면 **실시간 집계·검색**에 맞는 저장소(NoSQL DB 등)가 필요하다.

### 분산 KVS — 디스크 쓰기 성능 향상

- **분산 KVS(Distributed Key-Value Store)**: 모든 데이터를 **key-value** 쌍으로 저장. 객체 스토리지보다 **작은 데이터**(몇 KB 수준)를 **초당 수만 번** 읽고 쓰는 경우를 가정한다.
- **키**로 클러스터 내 노드 배치가 결정되어 부하 분산이 되고, 노드 증감으로 성능을 조절할 수 있다. 키당 하나의 값, 또는 키·값 조합 방식은 제품마다 다르다.

**예: Amazon DynamoDB**

- 안정된 읽기/쓰기 성능을 위한 분산 NoSQL. 1~2개 키에 스키마리스·중첩(JSON) 데이터 저장 가능. 도큐먼트 스토어처럼도 사용 가능.
- **P2P 분산 아키텍처**, 초 단위 요청 수에 따라 노드가 자동 증감. 사용자 요청에 고유 ID를 붙여 저장하는 등 **지연에 민감한 앱**에 적합.
- 분석 시: EMR, Redshift 등과 연동해 Hive 배치 처리·DW 전송. **DynamoDB Streams**로 변경 이벤트를 외부로 보내 스트림 처리 가능.
- NoSQL은 보통 **대량 집계 기능**이 없어 분석 시에는 외부로 추출해야 한다. 다만 읽기 성능이 좋아 **쿼리 엔진에서 직접 연결**해 애드 혹 분석에 쓰는 경우도 있다.

### 와이드 컬럼 스토어 — 구조화 데이터를 분석해 저장

- **와이드 컬럼 스토어**: 2개 이상의 키에 데이터를 저장. (예: Google Bigtable, Apache HBase, **Apache Cassandra**)
- **행 키 + 컬럼명** 조합으로 값을 저장. 행·컬럼을 자유롭게 추가할 수 있어, 하나의 테이블에 2차원(가로·세로)으로 데이터를 쓴다.

**Apache Cassandra**

- 내부는 와이드 컬럼 스토어, **CQL**이라는 쿼리 언어로 SQL과 비슷하게 테이블을 조작. 스키마를 먼저 정해야 해서 **구조화 데이터**만 다룬다.
- `INSERT`는 **upsert**(같은 키면 덮어쓰기)로 동작하는 등 SQL과 의미가 다르다.
- **P2P 분산**, 지정한 키에 따라 해당 키의 데이터가 한 노드에 모인다. 사용자 ID를 키로 하면 사용자별 기록이 한 노드에 모여 **사용자별 타임라인** 구성에 적합.
- **복합 키(compound key)** 로 거대한 테이블을 구현. 집계 자체는 모든 노드에서 데이터를 모아야 해서 비효율적이므로, **Hive, Presto, Spark** 등 쿼리 엔진으로 추출해 분석한다.

### 도큐먼트 스토어 — 스키마리스 데이터 관리

- **도큐먼트 스토어**: 와이드 컬럼이 성능 중심이라면, 여기서는 **유연한 데이터 처리**가 목적. JSON처럼 **중첩·스키마리스** 데이터를 그대로 저장하고 쿼리할 수 있다.
- 배열·맵 등에 **인덱스**를 만들거나, **도큐먼트 일부만 치환**하는 쿼리가 가능. 스키마를 정하지 않고 처리할 수 있어 **외부에서 가져온 데이터·로그** 저장에 적합하다.
- (참고: 최근 RDB에도 도큐먼트 기능이 들어오며, 높은 신뢰성이 필요하면 RDB 트랜잭션 안에서 도큐먼트를 다루는 경우가 많다.)

**MongoDB**

- 오픈소스 분산 도큐먼트 스토어. 여러 언어로 읽고 쓸 수 있다. 과거에는 성능 우선·신뢰성 희생으로 비판도 있었으나 편의성으로 인기가 높다.
- 여러 노드에 분산 가능하지만 **대량 집계에는 부적합**. 분석 목적이면 쿼리 엔진으로 접속해 데이터를 꺼내는 구성이 일반적이다.

### 검색 엔진 — 키워드 검색

- **검색 엔진**: NoSQL과 성격은 다르지만, 저장된 데이터를 쿼리로 찾는다는 점에서는 비슷하다. **텍스트·스키마리스 데이터** 집계에 자주 쓴다.
- **역 색인(inverted index)** 를 만들어 **전문 검색**을 고속화한다. 저장 시 부하는 커지지만 **검색 성능**이 크게 좋아진다.
- NoSQL이 인덱스를 제한하는 것과 달리, 검색 엔진은 **적극적으로 인덱스**를 만들어 검색에 특화된다. **비정상 감지, 보안, 고객 지원**처럼 **최근 데이터를 빠르게 보는** 용도, **실시간 집계 시스템의 일부**로 쓰인다. 장기 축적보다는 **실시간성**이 중요할 때 사용한다.
- 메시지 브로커가 분산 스토리지에 저장하는 동시에 **같은 데이터를 검색 엔진**에도 보내 실시간 처리에 활용하는 구성이 흔하다.

**Elasticsearch**

- 오픈소스 검색 엔진. **Logstash**(수집), **Kibana**(시각화)와 함께 **ELK/Elastic 스택**으로 사용.
- 임의 JSON 저장 가능. 기본적으로 **모든 필드에 인덱스**가 만들어져, 쓰기 부하가 크다. 스키마를 명시해 인덱스를 줄이는 등 튜닝이 필요할 수 있다.
- 자체 쿼리 언어로 고급 집계 제공. 열 지향 스토리지 대응으로 집계 기반으로도 쓸 수 있으나, 표준 쿼리 언어가 복잡해 **Kibana** 같은 프론트엔드나 프로그램에서 호출하는 방식이 일반적이다.
- (참고: 데이터 규모가 매우 크면 색인 자체가 어려운 경우도 있어, 대규모에서는 log→kafka→flink→Iceberg 등 다른 파이프라인을 쓰는 사례가 있다.)

**Splunk**

- 상용 검색 엔진. **비정형 데이터**(웹 서버·네트워크 로그, JSON 등)를 텍스트 처리해 분석하는 데 쓰인다.
- 키워드 검색으로 로그를 찾고, **패턴 매치**로 필드(키·값)를 추출한다. 검색할 때마다 데이터가 구조화되므로, 쿼리를 바꿔 **유연하게 테이블**을 만든다.
- **파이프(`|`)로 순차 가공**하는 대화형 쿼리로 추출·필터·교차분석·시각화까지 한 화면에서 할 수 있어, 텍스트 데이터의 **애드 혹 분석**에 유용하다.

### 일반 NoSQL과 검색 엔진의 집계 능력 차이

- NoSQL: 읽기/쓰기 성능에 강점, **대량 집계**는 쿼리 엔진과 연동해 추출 후 분석.
- 검색 엔진: **인덱스·역 색인**으로 검색·집계에 특화, 실시간·최근 데이터 조회에 적합.

---

## 4-5 정리

> **※ 아래 4-5 절 내용은 다음 출처를 바탕으로 정리하였습니다. 출처: https://jinyshin.notion.site/8-14a4cff7232680c1b8e9d05fcc9970a8 (8회차 스터디 내용 준비)**

이 장에서는 **데이터를 모아 분산 스토리지에 저장**하기까지의 **데이터 수집 흐름**을 다뤘다.

- 빅데이터를 효율적으로 집계하려면 **장기 데이터 분석**을 전제로 한 **스토리지** 구성이 필요하며, 데이터 도입 프로세스는 복잡하다.
- 데이터를 **너무 자주** 복사하면 데이터가 잘게 쪼개져 **집계 효율**이 나빠진다.
- **벌크형**: 한 번에 대량 복사라 상대적으로 단순. **스트리밍형**: 작은 메시지가 대량으로 들어오므로 **정기적으로 모아서 기록**하는 설계가 필요하다.
- **다수 클라이언트**에서 실시간 수집에는 **메시지 배송**이 쓰인다. **메시지 브로커** 도입으로 분산 스토리지 쓰기 **속도를 안정화**하고, 메시지를 **여러 경로로 라우팅**해 **스트리밍 처리와 배치 처리** 모두에서 같은 데이터를 쓸 수 있다.
- 메시지 배송은 **트랜잭션을 쓰지 않는** 경우가 많아 **중복·누락** 가능성이 있다. 보통 **at least once**로 누락을 피하고, **중복 제거는 개발자 책임**이다. **소량 중복 허용** + **신뢰성이 중요한 구간은 벌크형** 사용이 일반적이다.
- **메시지 배송 대신** 애플리케이션에서 **NoSQL 등 분산 스토리지**에 직접 쓰는 방법도 있다. NoSQL은 읽기/쓰기는 우수하지만 **대량 집계**는 부족하다. **쿼리 엔진과 연결해 애드 혹 분석**하거나 **정기적으로 꺼내 장기 분석용**으로 준비하는 구성이 필요하다.

---

## 참고

- **4-1~4-2 정리 출처: https://boleesystem.tistory.com/1031** (데브아티스트 : 보리의 개발기록)
- **4-3~4-5 정리 출처: https://jinyshin.notion.site/8-14a4cff7232680c1b8e9d05fcc9970a8** (8회차 스터디 내용 준비)
- 빅데이터를 지탱하는 기술 https://product.kyobobook.co.kr/detail/S000001916916
- [J_Bin 빅데이터를 지탱하는 기술 CHAPTER 4 : 빅데이터의 축적 (4-5)](https://jbin0512.tistory.com/287)
