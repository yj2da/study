# 5. 빅데이터의 파이프라인

> 백필할때
> 왜 실행 속도를 낮춰서 부하를 떨어트리는게 해결이 될까? 왜 오류가 난 태스크를 재실행하면 성공할까?

## 5.1 워크플로 관리

> 정기적인 데이터 관리를 자동화하여 안정된 배치 처리를 실행하기 위해 워크플로 관리 도구를 도입

### [기초 지식] 워크플로 관리 - 데이터의 흐름을 일원 관리하기

일상적인 업무에는 수동으로 하는 것곽 자동화된 것이 있는데, 여기서는 자동화된 워크플로만을 가정한다.
태스크는 정해진 스캐줄에 따라 자동으로 실행되고, 무언가 비정상적 일이 발생한 경우에는 사람이 개입하여 문제를 해결한다.

#### 워크플로 관리 도구

주요 역할

- 정기적으로 태스크를 실행
- 비정상적인 상태를 감지하여 그것에 대한 해결을 돕는 것

오픈 소스의 워크플로 관리 도구의 예

| 이름                                         | 종류        | 개발사                         |
| -------------------------------------------- | ----------- | ------------------------------ |
| [Airflow](https://github.com/apache/airflow) | 스크립트 형 | Airbnb                         |
| Azkaban                                      | 선언형      | Linkedin                       |
| Digdag                                       | 선언형      | 트레주어 데이터                |
| Luigi                                        | 스크립트 형 | Spotify                        |
| Oozie                                        | 선언형      | The Apache Software Foundation |

#### 워크플로 관리 도구와 태스크

데이터 파이프라인의 실행 과정에서는 데이터를 잇달아 이동하면서 정해진 처리를 반복한다.
이때 실행되는 개별 처리를 '태스크(task)'라고 부른다.
태스크를 단지 실행하는 것만이라면 특별한 도구 필요 없이 자신이 직접 만든 스크립트를 실행시키는 것만으로도 데이터 파이프라인을 실현할 수 있다.

![workflow_task](./img/workflow_task.png)

#### 기본 기능과 빅데이터에서 요구되는 기능

워크플로 관리를 위해 전용 도구를 사용하는 이유 : 태스크 실행에 실패할 수 있기 때문이다.

데이터 파이프라인이 복잡해지거나, 태스크의 수가 증가하면 실패한 태스크를 다시 실행하는 일 또한 점차 어려워진다.

워크플로 관리 도구는 주로 다음과 같은 기능을 제공한다.

- 태스크를 **정기적인 스케줄로 실행**하고 그 결과 통지하기
- 태스크 간의 **의존 관계**를 정하고, 정해진 **순서**대로 빠짐없이 실행하기
- 태스크의 실행 결과를 보관하고, 오류 발생 시에는 **재실행**할 수 있도록 하기

#### 선언 형과 스크립트 형 - 워크플로 관리 도구의 종류

'선언형(declarative) 도구'

- XML이나 YAML 등의 서식으로 워크플로를 기술하는 타입 (Oozie)
- 선언형 도구에서는 **미리 제공된 기능**만 이용할 수 있는데, 그 범위 안이라면 최소한의 기술로 태스크를 정의 가능
- 누가 작성해도 동일한 워크플로가 되기 때문에 유지 보수성이 높다
- 동일 쿼리를 파라미터만 바꾸어 여러 번 실행하거나, 워크플로를 단순 반복적으로 자동 생성하는 경우에도 선언형 도구가 사용

```xml
<workflow-app name ='wordcount-wf' xmlns="uri:oozie:workflow:0.1">
    <start to='wordcount'/>
    <action name='wordcount'>
        <map-reduce>
            <job-tracter>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <configuration>
            ...
            </configuration>
        </map-reduce>
    </action>
</workflow-app>
```

'스크립트 형(Script) 도구'

- 스크립트 언어로 워크플로를 정의하는 유형 (Airflow)
- 스크립트 형의 특징은 그 유연성
- 일반적인 스크립트와 동일하게 변수나 제어 구문을 사용할 수 있으므로, 태스크의 정의를 프로그램이 한다
- 스크립트 언어에 의해 데이터 처리를 태스크 안에서 실행하는 것도 가능
- 예) 파일의 문자 코드를 변환하면서 서버에 업로드하는 식의 태스크는 스크립트 형 도구의 강점

```bash
# 쉘 스크립트의 ㅌ메플릿 정의
SCRIPT = '''
aws s3 cp --recursive s3://example/logs/{{ ds }}/ .
'''

# 쉘 스크립트를 실행하는 태스크 등록
task = BashOperator(task_id='data_transfer', bash_command=SCRIPT)
```

#### 오류로부터의 복구 방법 먼저 생각하기

데이터 파이프라인을 매일 동작시키다 보면, 뭔가 예기치 못한 오류가 분명 발생한다.
그것이 일시적인 장애든지 구현상의 버그든지 신속하게 문제를 해결하여 태스크를 재실행해야 한다.

예)

- 1일의 액세스 로그를 집계하는데 4시간의 배치 처리를 동작
- 만약 이 처리가 실패하여 다시 4시간에 걸쳐 재시도한다면, 그날의 워크플로에 큰 지연이 발생
- 후속의 태스크 중에는 예정된 시간까지 끝내지 않으면 새로운 문제를 일으키는 태스크가 있을지도 모름
- 그러면 하나의 실패가 연쇄적으로 확대돼서 결과적으로는 모든 태스크를 처음부터 다시 시작해야 하므로 하루를 낭비

빅데이터를 취급하고 있으면 다양한 오류가 발생한다.

- 네트워크의 일시적인 장애
- 하드웨어의 장애를 비롯하여 스토리지 용량 부족
- 쿼리 증가에 따른 성능 부족 등
- 일상적인 요인에서 발생하는 것부터 그다지 발생하지 않는 것까지 다양하다.

그 모든 것을 사전에 예상하는 것은 불가능하므로, 미리 예기치 못한 오류가 발생할 가능성을 고려하여 오류 발생 시의 대처 방법을 미리 결정해두는 것이 중요하다.

워크플로 관리에서는 태스크의 실행 순서를 정하는 것과 동시에 오류로부터 어떻게 회복할 것인가라는 계획을 정한다.

무엇인가 문제가 발생해도 신속하게 회복할 수 있도록 오류에 강한 워크플로를 구축하여 매일 반복되는 데이터 처리를 안정적으로 실행할 수 있도록 노력한다.

#### 복구와 플로우의 재실행

오류에는 수많은 가능성이 있으므로 기본적으로 워크플로 관리에서는 오류로부터 자동 회복할 수 있다는 점은 고려하지 않는다.

대신에 수작업에 의한 '복구(recovery)'를 전제한 태스크를 설계한다. 실패한 태스크는 모두 기록하여 그것을 나중에 재실행할 수 있도록 한다.

![workflow_restart_task](./img/workflow_restart_task.png)

여기서는 워크플로 관리 도구에 의해 실행되는 일련의 태스크를 '플로우(flow)'라고 한다.

각 플로우에는 실행 시에 고정 파라미터가 부여되어 있다.

- 일별 배치 처리라면 특정 날짜가 파라미터

동일 플로우에 동일 파라미터를 건네면 완전히 동일한 태스크가 실행되도록한다. 이유는 플로우가 도중에 실패해도 나중에 동일 파라미터로 재실행이 가능하기 때문이다.

이것이 복구의 기초다.

대부분의 워크플로 관리 도구는 과거에 실행한 플로우와 그 파라미터를 자동으로 데이터베이스에 기록하게 되어 있다. 그래서 실패한 플로우를 선택하여 재실행하는 것만으로 복구가 완료된다. 웹 브라우저로 오류의 상세 내용을 확인하고 클릭 한 번으로 재실행할 수 있는 도구를 선택하면 좋을 것이다. 대부분 오류는 일시적인 것이 많아 시간을 두고 재실행하는 것만으로도 해결되는 경우가 많기 때문이다.

TIP: 태스크를 되도록 작게 유지하기

- 빅데이터의 워크플로는 시간이 오래 걸리는 것도 있기 때문에, 오류가 발생할 때마다 처음부터 재실행하는 것은 너무 많은 시간이 걸린다

#### 재시도 - 여러 차례 반복되는 오류는 자동화하고 싶다

여러 번 발생하는 오류에 대해서는 되도록 자동화하여 수작업 없이 복구하고 싶을 것이다. 간단한 것은 태스크 단위의 자동적인 '재시도(retry)', 즉 단순한 재실행이다. 곧바로 재시도해도 실패를 반복하는 일이 많기 때문에, 재시도 간격을 5분 or 10분 정도로 두면 성공할 수 있다.

재시도를 반복해도 문제가 없는 태스크라면, 1회나 2회의 재시도를 실행해도 좋을 것이다. 그러나 그 이상은 태스크의 재시도로 대처하는 것이 아니라 올바른 문제 해결 방법을 찾아야 한다.

#### 백필 - 일정 기간의 플로우를 연속해서 실행하는 구조

실패한 플로우를 복구하는 다른 하나의 수단은 플로우 전체를 처음부터 다시 실행하는 것이다. 이를 위해 이용할 수 있는 것이 '백필(backfill)'의 기능이다.

백필

- 파라미터에 포함된 일시를 순서대로 바꿔가면서 일정 기간의 플로우를 연속해서 실행하는 구조
- 태스크의 실패가 며칠 동안이나 계쏙된 후에 이를 모두 모아서 재실행하고 싶을 경우
- 새롭게 만든 워크플로를 과거로 거슬러 올라가 실행하고 싶은 경우

![workflow_backfill](./img/workflow_backfill.png)

대규모의 백필을 실시할 때는 자동적인 재시도는 모두 무효로 하고, 오류는 모두 통지하는 편이 좋다. 테스트 삼아 조금씩 백필을 실행하여 어떠한 오류가 발생했는지, 오류가 발생하지 않는지를 확인한다.

오류가 자주 발생하면, 실행 속도를 낮춰서 부하를 떨어뜨려야 한다.

마지막에 오류가 난 태스크만을 재실행하면 모든 백필이 완료된다.

### 멱등한 조작으로 태스크를 기술하기 - 동일 태스크를 여러번 실행해도 동일한 결과가 된다

#### 원자성 조작

예를 들어 SQL을 실행하는 태스크가 있고, 그 안에 INSERT 문을 2회 호출하고 있다고 하자. 만약 첫 번째의 INSERT가 종료한 상황에서 오류가 발생하면, 태스크가 재실행된 때에 동일한 데이터가 다시 쓰이게 될 수 있다.

![workflow_duplicate_data](img/workflow_duplicate_data.png)

적어도 워크플로 관리 도구에 의해 자동적인 재시도는 피하고, 오류의 내용을 반드시 확인한 뒤에 수동으로 복구해야 한다.

#### 멱등한 조작 - 추가와 치한

더욱 확실한 것은 '동일한 태스크를 여러 번 실행해도 동일한 결과'가 되도록 하는 것이다. 이것을 '멱등한 조작(idempotent operation)'이라고 부른다. SQL이라면 '테이블을 삭제한 후에 다시 만들기'가 멱등한 조작의 예다.

```sql
DROP TABLE IF EXISTS "t1";
CREATE TABLE "t1";
INSERT INTO "t1" ...;
```

#### 멱등항 추가

과거의 데이터를 치환하면 멱등하게 되긴 하지만, 그러면 부하가 커진다. 그래서 준비한 것이 '테이블 파티셔닝' 사고방식이다. 예를 들면, 테이블을 1일마다 또는 1시간마다 파티션으로 분할하고, 파티션 단위로 치환하도록 한다.

![workflow_partitioning](img/workflow_partitioning.png)

태스크를 멱등으로 구성하는 것이 어렵다면, 그것을 포기하고 원자성을 지닌 추가만으로 운영한다. 그 경우, 태스크를 재실행하면 데이터가 중복될 가능성이 있으므로, 자동적인 재시도는 반드시 무효로 하고, 오류 발생 시에는 수작업으로 복구하는 편이 좋다.

#### 원자성을 지닌 추가

복잡한 플로우에서는 하나의 테이블에 몇 번이고 데이터를 써넣을 때가 있다. 그 경우에는 추가를 반복하는 것이 아니라 중간 테이블을 만들어 처리한 후, 마지막에 목적 테이블에 한 번에 추가하는 것이 안전하다.

이렇게 하면 만약 플로우의 실행 도중에 문제가 발생해도 어정쩡하게 데이터가 쓰이는 일이 없으며, 최악의 걍우 중간 테이블을 삭제하여 다시 한번 처음부터 재실행할 수 있다

![workflow_temp_table](img/workflow_temp_table.png)

```sql
DROP TABLE IF EXISTS "t1";
CREATE TABLE "t1";
INSERT INTO "t1" ...;
INSERT INTO "t1" ...;

INSERT INTO "target_table"
SELECT * FROM "t1";
```

### 워크플로 전체를 멱등으로 하기

데이터 마트를 구축하는 플로우에서도 되도록 추가는 삼가고 테이블마다 치환하도록 한다. 그 과정에서 만들어진 중간 테이블도 가능한 한 치환하는 것이 바람직하지만, 성능상의 이유 등으로 추가해야 할 경우도 있다.

각 태스크를 멱등으로 하는 것이 이상적이지만 필수는 아니다. 최종적으로 워크플로가 안정적으로 실행되고 있는 한, 태스크가 멱등이지 않아도 동작에 지장은 없다.

![workflow_idempotent](img/workflow_idempotent.png)

### 태스크 큐 - 자원의 소비량 컨트롤하기

워크플로 관리 도구에서 요구되는 다른 하나의 커다란 역할은 외부 시스템의 부하 컨트롤이다. 태스크의 크기나 동시 실행 수를 변화시킴으로써 자원의 소비량을 조정하여 모든 태스크가 원활하게 실행되도록 한다.

너무 대량의 태스크를 동시 실행하면 서버에 과부하가 걸리므로 어느 정도 제한을 해야 한다. 이때 사용할 수 있는 것이 '잡 큐(job queue)' 또는 '태스크 큐(task queue)'라고 불리는 구조다. 모든 태스크는 일단 큐에 저장되고 일정 수의 워커 프로세스가 그것을 순서대로 꺼내면서 병렬화가 실현된다.

밑의 사진의 경우 8개의 워커를 가동하면, 8개가 병렬로 태스크 실행될 수 있다.

![workflow_task_queue](img/workflow_task_queue.png)

#### 병목 현상의 해소

워커의 수를 늘리면 좀 더 실행 속도를 높일 수 있다. 8코어의 서버라면 20개 정도의 태스크를 동시에 실행해도 문제없을 것이다. 단, 워커를 너무 증가시키면 어디선가 병목 현상이 발생해서 성능의 향상이 한계점에 도달하거나 오류가 발생한다.

워크플로 실행 시에 자주 발생하는 문제(서버의 내부적인 요인)

| 증상                  | 대책                                                                 |
| --------------------- | -------------------------------------------------------------------- |
| CPU 사용률 100%       | CPU 코어 수를 늘린다. 서버를 증설한다.                               |
| 메모리 부족           | 메모리를 증설한다. 스왑 디스크를 추가한다. 태스크를 작게 분할한다.   |
| 디스크 넘침           | 각 태스크가 임시 파일을 삭제하고 있는지 확인한다. 디스크를 증설한다. |
| 디스크 I/O의 한계     | SSD 등의 고속 디스크를 사용한다. 여러 디스크로 분산한다.             |
| 네트워크 대역의 한계  | 고속 네트워크를 사용한다. 데이터의 압축률을 높인다.                  |
| 통신 오류나 타임 아웃 | 시스템 상의 한계일 가능성이 있다. 서버를 분리한다.                   |

#### 태스크 수위 적정화 - 너무 크거나 너무 작지 않은 정도로 잘 분할하기

처음부터 '하나의 파일 전송을 하나의 태스크'로 고려한 것이 문제였다. 작은 태스크를 다수 실행하면 오버헤드만 커져서 실행 시간이 증가하고 오류 발생률을 높이는 요인이 된다. 하나의 파일을 5초에 처리할 수 있다면, 수백 개의 파일 정도를 모아서 하나의 태스크로 하는 것이 적정한 크기다.

태스크에는 날짜와 시간이 파라미터로 건네진다는 점을 기억하자. 각 태스크는 지정된 시간의 데이터를 모아 처리하도록 구현한다. 예를 들어, 파일이 1년 걸려서 만들어 진 것이라면 태스크를 1일마다 나눔으로써 생성되는 태스크의 수는 365개까지 줄일 수 있다.

![workflow_daily_task](img/workflow_daily_task.png)

태스크가 너무 클 경우에는 나누고, 너무 작을 경우에는 하나로 모음으로써 각 태스크가 적절한 크기가 될 수 있도록 조정한다. 그 다음에 여러 태스크를 동시에 실행하도록 워크의 수를 늘려 두면, 한정된 계산 자원을 낭비하지 않고 활용할 수 있다.

---

## 5.2 배치 형의 데이터 플로우

> **※ 아래 5.2~5.4 절 내용은 다음 출처를 바탕으로 정리하였습니다. 출처: https://boleesystem.tistory.com/1041 (데브아티스트 : 보리의 개발기록)**

### 1) MapReduce의 시대는 끝났다 — 데이터 플로우와 워크플로

- **데이터 플로우**: 분산 스토리지로의 데이터 전송이 끝나면, 분산 시스템 프레임워크로 **SQL뿐 아니라 프로그래밍 언어**로 데이터 파이프라인을 작성한다. 기술 발전으로 **다단계 데이터 처리를 분산 시스템 내부에서 한 번에 실행**할 수 있게 되었다.
  - 예전에는 MapReduce 프로그램을 워크플로의 태스크로 등록해 다단계 처리를 했다.
- **데이터 플로우용 프레임워크**: Google Cloud Dataflow, Apache Spark, Apache Flink 등.
- **MapReduce 구조**
  - 원본 데이터를 일정 크기로 나눈 **split** 생성 → **[Map]** split을 읽어 단어별 카운트(분산 가능) → **[Reduce]** 단어별 합계.
  - Map과 Reduce를 **반복**해 결과를 얻는 구조. 한 사이클이 끝나야 다음으로 넘어가므로 **사이클 간 대기 시간**이 크다.
- **MapReduce의 한계**: 지연이 적은 집계(애드 혹 분석에 필요한)를 MapReduce만으로 구현하기 어렵다.

### 2) MapReduce를 대신할 새로운 프레임워크 — DAG에 의한 내부 표현

- **MapReduce 대체**: Google MillWheel(Dataflow 내부), Hadoop Tez, Spark 등.
- **DAG(Directed Acyclic Graph, 방향성 비순환 그래프)**: 수학·알고리즘에서 쓰는 **데이터 모델**. 노드가 화살표로 연결되고(방향성), 따라가도 같은 노드로 돌아오지 않음(비순환).
- **MapReduce의 DAG**: Map·Reduce 두 종류 노드로 된 단순한 DAG. 한 노드가 끝나야 다음으로 가서 **비효율**.
- **데이터 플로우의 DAG**: 각 노드가 **동시에 병렬 실행**되고, 끝난 데이터만 다음으로 전달되어 **MapReduce 같은 대기 시간이 없다**.
- **Spark의 DAG**: **지연 평가(lazy evaluation)**. 먼저 DAG를 만들고, 실행 결과가 필요할 때 처리 시작. Map/Reduce를 차례로 돌리는 것이 아니라 **파이프라인 전체를 DAG로 조립한 뒤** 실행해, 스케줄러가 분산에 맞는 실행 계획을 세운다.

### 3) 데이터 플로우와 워크플로를 조합하기

- 데이터 플로우로 **입출력을 하나의 DAG**로 기술할 수 있지만, **정기 실행·실패 기록·복구**는 데이터 플로우만으로는 어렵다. 데이터 플로우는 **워크플로의 한 태스크**로 두는 것이 좋다.
- **데이터를 읽어들이는 플로우**
  - 데이터 플로우가 읽는 데이터는 **성능이 안정된 분산 스토리지**에 둔다. 데이터 소스 직접 접근은 성능 이슈가 있으므로, **워크플로**로 벌크 전송 도구를 써서 분산 스토리지에 복사한 뒤, 데이터 플로우에서는 그 스토리지만 사용한다. 오류 시 **복사를 끝까지 수행**하는 것이 우선이다.
- **데이터를 쓰는 플로우**
  - 집계 결과를 **외부 시스템에 직접 쓰는 것**은 피하는 편이 낫다. 데이터 플로우에서는 **CSV** 등 다루기 쉬운 형식으로 바꿔 **분산 스토리지에만 쓰고**, **워크플로**가 외부 시스템으로 전송한다.

### 4) 데이터 플로우와 SQL을 나누어 사용하기

| 구분 | 파이프라인 | 데이터 플로우의 역할 |
|------|------------|----------------------|
| **데이터 웨어하우스** | MPP DB에서 SQL 실행 | **로드되는 데이터를 만드는 것까지**. 비구조화 데이터를 가공해 CSV 등을 분산 스토리지에 저장 → 워크플로로 태스크·SQL 실행. |
| **데이터 마트** | 분산 시스템의 쿼리 엔진에서 SQL | **구조화 데이터를 만드는 부분까지**. 분산 스토리지 데이터를 배치로 가공해 열 지향 스토리지로 저장 → 워크플로로 SQL(쿼리 엔진) 실행 또는 결과를 데이터 마트에 전송. |
| **애드 혹 분석** | 수작업 중심, 워크플로 불필요 | **아직 구조화되지 않은 데이터**를 다룰 때 데이터 플로우가 유용. 로우 데이터에 접속해 스크립트로 가공·집계해 구조화 → 구조화된 데이터는 쿼리 엔진으로 고속 집계. **이미 구조화된 데이터**는 쿼리 엔진(ODBC/JDBC)·시각화 도구로 직접 접속. 안정적인 워크플로를 원하면 RDB·MPP DB를 데이터 마트로 두는 구성이 확실하다. |

---

## 5.3 스트리밍 형의 데이터 플로우

실시간성을 높이려면 **배치와 다른** 데이터 파이프라인이 필요하다. **DAG 기반 스트림 처리**가 그 한 축이다.

### 1) 배치 처리와 스트림 처리로 경로 나누기

- **배치 중심 파이프라인의 단점**: 집계까지 **시간이 걸린다**. **실시간성**(이벤트 발생 후 몇 초 안에 결과)이 필요하면 **스트림 처리**를 도입한다.
- **실시간 시스템 예**: 시스템 모니터링(서버·네트워크 상태 그래프), 로그 관리(비정상 시 경고), CEP(복합 이벤트 처리).
- **배치 vs 스트림**
  - **배치**: **과거** 데이터 집계. 도착한 데이터를 **분산 스토리지**에 저장 → **정기적으로** 추출해 처리(예: 1시간 단위). 데이터가 보존되어 **재실행 가능**. **1년 이상** 같은 장기 분석을 가정해 열 지향 스토리지를 구축하는 데 적합.
  - **스트림**: **실시간** 집계. 데이터 도착과 **거의 동시에** 처리 시작(끊임없이 DAG로 들어오며 진행). 과거로 돌아가 재실행하는 것은 전제하지 않음. 결과는 **시계열 DB** 등에 저장하거나 기존 실시간 시스템으로 전송.

### 2) 배치 처리와 스트림 처리 통합하기

- **유한(bounded) 데이터**: 실행 시 데이터 양이 정해짐. **무한(unbounded) 데이터**: 제한 없이 계속 들어옴. 공통점은 **작은 단위로 나눠 DAG에서 실행**한다는 것.
- **동일 DAG로 배치·스트림 둘 다**: 스트림용 DAG를 바꿔서 분산 스토리지의 **과거 데이터**를 읽게 하면 **배치 처리**로도 쓸 수 있다.
- **Spark 스트리밍**: Spark는 원래 배치용이지만 스트리밍 기능으로 **스트림 처리**까지 가능. **읽기/쓰기 초기화**만 다르고, **처리 로직은 배치·스트리밍이 같다**.
- **스트림으로 1차 집계**: 1초마다 통곗값만 남기거나, 데이터 양을 줄이기 위해 스트림 처리로 먼저 삭감할 수 있다. 스트림 결과를 메시지 브로커에 다시 써서, 삭감된 데이터를 배치용 분산 스토리지·실시간 보고용 시계열 DB 등으로 보낼 수 있다.

### 3) 스트림 처리의 결과를 배치 처리로 치환하기 — 스트림의 두 가지 문제와 대응

- **스트림 처리의 한계**
  1. 잘못된 결과를 **수정하기 어렵다**(과거로 되돌리는 개념이 없음).
  2. **집계가 끝난 뒤 도착하는 데이터** 때문에 결과가 부정확해질 수 있다.
- **전통적 대응**: 스트림과 **별도로 배치**를 돌리고, **배치 결과를 정답**으로 둔다. 스트림 결과는 배치 결과가 나올 때까지 **잠정값**으로만 쓴다.
- **람다 아키텍처**: 파이프라인을 3개 레이어로 나눔.
  - **배치 레이어**: 모든 데이터를 여기서 처리. 과거 데이터를 장기 스토리지에 쌓고 재집계. 1회 처리에 시간이 오래 걸림.
  - **서빙 레이어**: 배치 결과를 **빠른 DB**에 두고 조회. **배치 뷰(batch view)** 는 정기 갱신되지만 실시간은 아님.
  - **스피드 레이어**: **스트림 처리**로 **실시간 뷰(realtime view)** 생성. 배치 뷰가 갱신될 때까지만 사용하고, 오래된 순으로 삭제. **배치 뷰 + 실시간 뷰**를 합쳐 쿼리.
  - **장점**: 실시간 뷰를 나중에 배치 뷰로 대체할 수 있어, 스트림만 재실행할 필요가 없다. **단점**: 스피드·배치 레이어에 **같은 로직을 두 번** 구현해야 해서 개발 효율이 떨어진다.
- **카파 아키텍처**: 배치·서빙 레이어를 없애고 **스피드 레이어만** 두는 단순화. 메시지 브로커 보관 기간을 길게 해, 문제 시 **과거 시점으로 재설정**해 출력을 덮어쓰는 방식. 배치처럼 과거 데이터 일괄 처리도 **스트림 처리만**으로 수행. 부하는 커지지만 클라우드로 자원 확보가 쉬운 경우에 선택한다.

### 4) 아웃 오브 오더(out-of-order) 데이터 처리

- **문제**: 늦게 도착하는 메시지(프로세스 시간과 이벤트 시간의 차이).
- **이벤트 시간**: 데이터가 **처음 생성된** 시간. 올바른 집계를 위해서는 **이벤트 시간** 기준이 필요하다. 도착 순간에 바로 집계하면 출력은 **프로세스 시간**에 묶여 혼란이 생길 수 있다.
- **이벤트 시간 윈도윙(event-time windowing)**: **이벤트 시간**으로 윈도우를 나누는 것. 도착 순서가 뒤섞인(**아웃 오브 오더**) 데이터를 **순서를 맞춰** 집계 결과를 갱신해야 한다.
- **구현 시 고려**: 과거 이벤트 상태를 유지하면서 도착할 때마다 **해당 윈도우를 다시 집계**해야 하고, **일정 이상 늦게 온 데이터는 버리는** 정책(watermark 등)이 필요하다.

---

## 5.4 정리

- **5.2 배치 형**: 데이터 플로우는 DAG로 다단계 처리를 한 번에 표현·실행. MapReduce 대신 Spark·Flink·Dataflow 등 사용. 데이터 플로우와 워크플로를 조합하고, DW/데이터 마트/애드 혹에 따라 데이터 플로우와 SQL 역할을 나눈다.
- **5.3 스트리밍 형**: 배치(과거·유한)와 스트림(실시간·무한)은 경로를 나누되, 같은 DAG로 둘 다 표현 가능. 스트림 결과는 부정확·수정 어려움 때문에 람다(배치 뷰로 치환) 또는 카파(스트림만 재처리)로 보완. 아웃 오브 오더는 이벤트 시간 윈도윙으로 다룬다.

---

## 출처

- https://product.kyobobook.co.kr/detail/S000001916916
- **5.2~5.4 절 정리 출처: https://boleesystem.tistory.com/1041** (데브아티스트 : 보리의 개발기록 — 배치/스트리밍 형의 데이터 플로우)
- https://jbin0512.tistory.com/288
