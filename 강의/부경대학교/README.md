# 데이터 엔지니어링 · 빅데이터 · 분산처리 기초 (5일 과정)

## 자기소개 및 인사

**유재호**
- 네이버 8년차 데이터 엔지니어
- 오픈소스 메인테이너: [Trino Gateway](https://github.com/trinodb/trino-gateway)
- 해외 거주 경험 10년+

## 과정 개요

| 항목          | 내용                                         |
| ------------- | -------------------------------------------- |
| **과정명**    | 데이터 엔지니어링 · 빅데이터 · 분산처리 기초 |
| **교육 대상** | 대학생                                       |
| **교육 수준** | 초급                                         |
| **교육 기간** | 5일 (1일 4시간, 총 20시간)                   |
| **교육 방식** | 이론 + 실습 병행 (4일) / 종합 실습 (1일)     |
| **교육 형태** | 오프라인 실습형                              |
| **사용 기술** | Linux, Docker, Spark(PySpark)                |

### ⚠️ 이 강의는 "맛보기" 과정입니다

**20시간 안에 모든 것을 다룰 수 없습니다**

이 과정은 데이터 엔지니어링의 **핵심 개념과 기본 실습**에 집중합니다.

각 기술의 세부적인 옵션, 고급 기능, 최적화 방법 등은 다루지 않습니다.

- ✅ 다루는 것: 핵심 개념, 기본 사용법, 실무 감각 익히기
- ❌ 다루지 않는 것: 모든 옵션, 고급 기능, 프로덕션 최적화

**강의 후 해야 할 일**

- 각 기술의 공식 문서를 읽으며 세부 기능 학습
- 개인 프로젝트로 실습 반복

---

## 강의 중 유의사항

### 질문과 소통

- **설명이 너무 빠르거나 이해가 안 되면 언제든지 멈춰달라고 말씀해주세요**
- 모든 사람이 아는 게 다르기 때문에, 어디까지 설명해야 하는지 기준이 다릅니다
- 여러분의 피드백을 통해 강의 속도와 깊이를 조절합니다
- **어떠한 질문도 다 환영합니다!**
  - 강의 내용·실습뿐 아니라
  - 네이버 회사 생활, 취업 팁, 오픈소스 메인테이너 경험, 해외 생활 등
  - 무엇이든 편하게 질문하세요

### ChatGPT 등 LLM 사용

- 개념 이해나 강의 중 궁금한 점은 ChatGPT, Claude, Gemini 등 LLM을 자유롭게 사용하셔도 됩니다
- **다만, 실습 문제를 풀 때는 왠만하면 사용을 자제해주세요**
  - **스스로 해보는 것이 중요합니다**
  - 실무에서 매번 모든 것을 LLM에 물어볼 수 없습니다
  - 공식 문서 읽기, 에러 메시지 해석, 이전 코드 참고 등의 능력이 필요합니다
- 정말 막혔을 때나, 실습 완료 후 개선 방법을 찾을 때 활용하세요

---

## 강의 방식의 특징

### 마크다운으로 강의하는 이유

이 강의는 PPT가 아닌 **마크다운 문서**로 진행됩니다.

**1. 실무에서 사용하는 방식**

실제 팀 내부 세미나에서 사용하는 방식입니다.

회사에서는 재택이 자유롭고 주 1회 출근하기 때문에, **큰 화면에 강의 자료를 띄우고 Zoom도 연결**해서 온라인으로도 볼 수 있게 합니다. Zoom에서 화면을 공유하면서 진행하고, 회의도 Zoom에서 많이 합니다.

이번 강의는 **오프라인으로 진행**되기 때문에, 화면에 자료를 띄워서 같이 보면서 진행할 예정입니다.
제 목소리가 너무 작다면 언제든지 말씀해 주세요.

**2. 개발자 친화적**

- 코드, 명령어 바로 복사 가능
- `Ctrl+F`로 검색 가능
- Git으로 버전 관리
- 강의 후 파일 그대로 공유

**3. 빠른 업데이트**

**실무 vs 학문의 차이:**

- 학문: 완벽하게 정리된 PPT, 발표 자료
- 실무: 빠르게 변하는 정보, 지속적인 업데이트
- **핵심**: KPI(Key Performance Indicator, 주요 성과 지표) 같은 중요한 발표가 아닌 이상, 예쁘게 만드는 시간보다 **빠르게 공유**하는 게 중요
- 이전에 공부했던 내용을 **다시 찾기 쉽게**, **수정하기 쉽게** 하는 것이 우선

**트렌드 변화:**

- 데이터 엔지니어링 업계는 트렌드가 빠르게 변화
- 오픈소스는 1년만 지나도 뒤쳐질 수 있음
- 마크다운이면 즉시 수정하고 최신 상태 유지 가능

---

## 5일 커리큘럼

강의 자료는 GitHub에서 확인할 수 있습니다:  
**📚 https://github.com/Chaho12/study/tree/main/강의/부경대학교**

> 강의 자료는 한 번에 모두 올리지 않고, 진행하면서 일부분씩 업로드할 예정입니다.

### Day 1. 데이터 엔지니어링 & 빅데이터 기초

- 데이터 엔지니어링 개념 및 역할
- 빅데이터와 분산 처리 개념
- Linux 기본 명령어 실습
- Docker 기반 실습 환경 구성

### Day 2. 분산 시스템/스토리지 기초

- NFS, CIFS, HDFS 개념
- 분산 저장 구조 이해
- HDFS 환경 구성
- 데이터 업로드 및 조회 실습

### Day 3. 분산 처리 기초 (Apache Spark)

- Spark 개념 및 처리 흐름
- PySpark 기본 사용법
- 데이터 필터링 및 집계 실습

### Day 4. 데이터 처리 흐름 만들기

- 배치 처리 개념
- 데이터 파이프라인 설계
- HDFS → Spark 데이터 처리
- ETL 프로세스 구현

### Day 5. 복습 & 종합 실습

- 전체 내용 리뷰
- 종합 데이터 처리 실습 (전자상거래 로그 분석)
- 추가 학습 자료 안내

---

## 학습 목표

1. 데이터 엔지니어링의 개념과 역할을 이해한다
2. 빅데이터와 분산 처리의 필요성을 이해한다
3. 분산 환경에서 데이터를 저장하고 처리하는 경험을 한다
4. 간단한 데이터 처리 파이프라인을 직접 구현해본다

---

## 준비물

### 필수

- 노트북 (Linux, macOS, Windows 모두 가능)
- Podman Desktop 설치 (또는 Docker Desktop)
- 터미널 접근 가능
- 최소 30GB 여유 디스크 공간
- 램 8GB 이상

### 권장

- Python 기본 문법 이해
- SQL 기본 지식
- 영어 문서 읽기에 대한 두려움 없애기

---

## 타임라인 (매일 반복)

> ⚠️ 아래 타임라인은 기본 계획이며, 실습 진행 상황과 질문 시간에 따라 유동적으로 조정될 수 있습니다.

| 구간  | 시간        | 소요   | 비고           |
| ----- | ----------- | ------ | -------------- |
| 1블록 | 13:00–14:15 | 1h 15m | 이론·개념 중심 |
| 휴식  | 14:15–14:30 | 15분   |                |
| 2블록 | 14:30–15:45 | 1h 15m | 실습·활동 중심 |
| 휴식  | 15:45–16:00 | 15분   |                |
| 3블록 | 16:00–17:00 | 1h     | 적용·정리·Q&A  |

---

## 참고 자료

### 공식 문서

- [Docker 공식 문서](https://docs.docker.com/)
- [HDFS 공식 문서](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html)
- [Spark 공식 문서](https://spark.apache.org/docs/latest/)
- [PySpark API 문서](https://spark.apache.org/docs/latest/api/python/)

### 추천 도서

> **💡 영문 원서가 있는 책은 가능하면 영문으로 읽으세요**
>
> 번역서도 좋지만, 기술 용어와 최신 개념을 정확히 이해하려면 원서를 읽는 것이 좋습니다.

---

#### 📚 데이터 엔지니어링 핵심 도서

**1. 견고한 데이터 엔지니어링** - 조 라이스, 맷 하우슬리

- [한글판](https://product.kyobobook.co.kr/detail/S000202731288) (한빛미디어)
- 원서: **Fundamentals of Data Engineering** (O'Reilly)
  > 가능하면 영문 원서 추천
- 데이터 엔지니어링 수명 주기 프레임워크
- 특정 도구가 아닌 기본 개념과 원칙 중심 (오래 유지되는 지식)
- 2024년 세종도서 학술 선정도서

**2. 빅데이터를 지탱하는 기술** - 니시다 케이스케

- [한글판](https://product.kyobobook.co.kr/detail/S000001916916) (제이펍)
- 시시각각 변하는 데이터를 파악하는 자동화의 세계
- 빅데이터 처리 과정의 전체 흐름과 기술 스택 정리
- 워크플로 관리, 스트림 처리 등 실무 자동화 기술

**3. Hadoop: The Definitive Guide (4th Edition)** - Tom White

- [영문 원서](https://product.kyobobook.co.kr/detail/S000003304670) (O'Reilly)
- Hadoop의 바이블, MapReduce/HDFS/YARN 완벽 가이드
- Parquet, Flume, Crunch, Spark 등 에코시스템 포함

---

#### 💻 개발 기본기

**4. 이펙티브 자바 (3판)** - 조슈아 블로크

- [한글판](https://product.kyobobook.co.kr/detail/S000001033066) (인사이트)
- 원서: **Effective Java** (Addison-Wesley)
  > 가능하면 영문 원서 추천
- Java 7, 8, 9 대응 (Java 26까지 나왔지만 기본 개념은 거의 동일)
- 자바 플랫폼 모범 사례와 함수형 프로그래밍

**5. 쿠버네티스 완벽 가이드** - 마사야 아오야마

- [한글판](https://product.kyobobook.co.kr/detail/S000001834656) (길벗)
- 입문부터 실제 운용까지 필요한 기술 총망라
- 쿠버네티스 1.18 기준, 300개 이상의 예제 제공

---

#### 🐧 Linux 기초 (필수)

**6. 유닉스 리눅스 프로그래밍 필수 유틸리티** - 백창우

- [한글판](https://product.kyobobook.co.kr/detail/S000001223682) (한빛미디어)
- **Linux 관련 책은 어떤 책이든 다 좋습니다**
- **이런 기본 서적은 기본기로 반드시 알아야 합니다**
- vim, gcc, make, gdb 등 필수 유틸리티 활용법
- 실무에서 바로 사용 가능한 실용적인 예제

---

## 중요한 마인드셋

> **"한국어 자료를 찾지 말고, 영어 공식 문서를 읽는 습관을 들이세요"**
>
> 데이터 엔지니어링 분야는 변화가 너무 빠릅니다. 1년 전 한국어 자료는 이미 구식일 수 있습니다.
> 영어 공식 문서를 읽는 것이 처음엔 어렵지만, 장기적으로 훨씬 효율적입니다.

---

## 라이선스

이 강의 자료는 학습 목적으로 자유롭게 사용 가능합니다.

**단, 다음 사항을 반드시 명시해야 합니다:**

- 출처: 데이터 엔지니어링 · 빅데이터 · 분산처리 기초 강의 자료
- 제공자: 유재호

---

## 피드백

강의 자료에 대한 피드백이나 개선 제안은 언제든 환영합니다.
