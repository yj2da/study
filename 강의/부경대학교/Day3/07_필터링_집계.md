# 07. 데이터 필터링 및 집계 실습

## 실습 목표

조건 필터링과 그룹별 집계를 수행합니다.

---

## 실습 단계

(06에서 이어서 진행. `df`가 이미 로드되어 있다고 가정)

### 1. 필터링

```python
# 나이가 30 이상인 사람
df.filter(df.age >= 30).show()

# 또는 where 사용 (동일)
df.where(df.age >= 30).show()

# 여러 조건 (AND) - 결과 없음 (30세 이상이면서 Seoul에 사는 사람이 없음)
df.filter((df.age >= 30) & (df.city == "Seoul")).show()

# 서울에 사는 사람 수
df.filter(df.city == "Seoul").count()
```

### 2. 집계

```python
# 도시별 평균 나이
df.groupBy("city").avg("age").show()

# 도시별 평균 연봉
df.groupBy("city").avg("salary").show()

# 여러 집계 함수
from pyspark.sql import functions as F

df.groupBy("city").agg(
    F.count("id").alias("count"),
    F.avg("age").alias("avg_age"),
    F.max("salary").alias("max_salary")
).show()
```

### 3. 정렬

```python
# 연봉 순으로 내림차순 정렬
df.orderBy("salary", ascending=False).show()

# 여러 컬럼으로 정렬
df.orderBy(["city", "age"]).show()
```

---

## 체크포인트

**"도시별 평균 연봉이 계산되었나요?"**

다음 코드를 실행해보세요:
```python
df.groupBy("city").agg(F.avg("salary").alias("avg_salary")).show()
```

<details>
<summary>정답 확인</summary>

예상 결과:
- Seoul: 52,500
- Busan: 62,500
- Incheon: 70,000

</details>

---

## 핵심 개념 정리

- `filter()` / `where()`: 조건에 맞는 행만 선택. 여러 조건은 `&`, `|` 사용.
- `groupBy().agg()`: 그룹별 집계. `F.count`, `F.avg`, `F.sum`, `F.max`, `F.min` 등.
- `orderBy()`: 정렬. `ascending=False`로 내림차순.

---

## 참고

- [08_HDFS_Spark_연동.md](08_HDFS_Spark_연동.md) — 다음 단계: HDFS와 Spark 연동 실습.

---

## 그림 출처

본 문서에는 인용한 외부 그림이 없습니다.
