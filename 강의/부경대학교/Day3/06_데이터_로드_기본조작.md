# 06. ë°ì´í„° ë¡œë“œ ë° ê¸°ë³¸ ì¡°ì‘

## ì‹¤ìŠµ ëª©í‘œ

PySparkë¡œ CSV ë°ì´í„°ë¥¼ ì½ê³ , ê¸°ë³¸ ì¡°íšŒÂ·ì„ íƒÂ·í†µê³„ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.

---

## ì‹¤ìŠµ ë‹¨ê³„

### 1. ìƒ˜í”Œ ë°ì´í„° ì¤€ë¹„

```bash
cat > ~/Desktop/data-engineering/day3/data/users.csv << 'EOF'
id,name,age,city,salary
1,Alice,25,Seoul,50000
2,Bob,30,Busan,60000
3,Charlie,35,Incheon,70000
4,David,28,Seoul,55000
5,Eve,32,Busan,65000
EOF
```

### 2. PySpark í™˜ê²½ ì ‘ì†

**ë°©ë²• 1: Jupyter Notebook ì‚¬ìš© (ê¶Œì¥)**

1. ë¸Œë¼ìš°ì €ì—ì„œ **http://localhost:8888** ì ‘ì†
2. ìƒˆ ë…¸íŠ¸ë¶ ìƒì„± (Python 3)
3. ì•„ë˜ ì½”ë“œë¡œ SparkSession ìƒì„±:

> ğŸ’¡ **Jupyter Notebook ì‚¬ìš© íŒ**: 
> - ì½”ë“œ ì…€ì— ì½”ë“œë¥¼ ì…ë ¥í•œ í›„ `Shift + Enter`ë¥¼ ëˆ„ë¥´ë©´ ì‹¤í–‰ë©ë‹ˆë‹¤.
> - ë˜ëŠ” ìƒë‹¨ì˜ â–¶ï¸ (Run) ë²„íŠ¼ì„ í´ë¦­í•´ë„ ë©ë‹ˆë‹¤.

```python
from pyspark.sql import SparkSession

spark = SparkSession.builder \
    .appName("DataLoadExample") \
    .master("spark://spark-master:7077") \
    .getOrCreate()
```

![spark_session_create](img/spark_session_create.png)
![spark_running_applications](img/spark_running_applications.png)

**ë°©ë²• 2: PySpark ì…¸ ì‚¬ìš©**

```bash
podman exec -it pyspark-notebook bash
pyspark --master spark://spark-master:7077
```

- `pyspark` ì…¸ì— ë“¤ì–´ê°€ë©´ `spark` ë³€ìˆ˜(SparkSession)ê°€ ì´ë¯¸ ìƒì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

> ğŸ’¡ **ê¶Œì¥**: Jupyter Notebookì„ ì‚¬ìš©í•˜ë©´ ì½”ë“œì™€ ê²°ê³¼ë¥¼ í•¨ê»˜ ì €ì¥í•˜ê³  ì‹œê°í™”í•  ìˆ˜ ìˆì–´ í•™ìŠµì— ë” íš¨ê³¼ì ì…ë‹ˆë‹¤.

### 3. ë°ì´í„° ë¡œë“œ

```python
# SparkSession í™•ì¸
spark

# CSV íŒŒì¼ ì½ê¸°
# ëª¨ë“  ì»¨í…Œì´ë„ˆê°€ ê³µìœ í•˜ëŠ” ê²½ë¡œ ì‚¬ìš©
df = spark.read.csv("/home/jovyan/work/data/users.csv", header=True, inferSchema=True)

# ë°ì´í„° í™•ì¸
df.show()
df.printSchema()
df.count()
```

> ğŸ’¡ **ê²½ë¡œ ì£¼ì˜**: 
> - ì»¨í…Œì´ë„ˆ ë‚´ë¶€: `/home/jovyan/work/data/users.csv` (ëª¨ë“  Spark ì»¨í…Œì´ë„ˆ ê³µí†µ)
> - Jupyter Lab íŒŒì¼ ë¸Œë¼ìš°ì €: `work/data/users.csv`
> - ë¡œì»¬ í˜¸ìŠ¤íŠ¸: `~/Desktop/data-engineering/day3/data/users.csv`

![spark_read_users](img/spark_read_users.png)

### 4. ê¸°ë³¸ ì¡°ì‘

```python
# ì»¬ëŸ¼ ì„ íƒ
df.select("name", "age").show()

# í†µê³„ ì •ë³´
df.describe().show()

# íŠ¹ì • ì»¬ëŸ¼ë§Œ í†µê³„
df.describe("age", "salary").show()
```

---

## ì²´í¬í¬ì¸íŠ¸

**"ë°ì´í„°ê°€ 5ê°œ í–‰ìœ¼ë¡œ ë³´ì´ë‚˜ìš”?"**

---

## í•µì‹¬ ê°œë… ì •ë¦¬

- `spark.read.csv()`: CSV íŒŒì¼ ë¡œë“œ. `header=True`, `inferSchema=True` ì˜µì…˜.
- `show()`, `printSchema()`, `count()`: ë°ì´í„° í™•ì¸ ê¸°ë³¸ ë©”ì„œë“œ.
- `select()`: ì›í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ.
- `describe()`: ê¸°ìˆ  í†µê³„(count, mean, stddev, min, max).

---

## ì°¸ê³ 

- [07_í•„í„°ë§_ì§‘ê³„.md](07_í•„í„°ë§_ì§‘ê³„.md) â€” ë‹¤ìŒ ë‹¨ê³„: í•„í„°ë§ ë° ì§‘ê³„.

---

## ê·¸ë¦¼ ì¶œì²˜

| íŒŒì¼ëª… | ì¶œì²˜ |
|--------|------|
| spark_session_create.png | ì§ì ‘ ìº¡ì²˜ |
| spark_running_applications.png | ì§ì ‘ ìº¡ì²˜ |
| spark_read_users.png | ì§ì ‘ ìº¡ì²˜ |
