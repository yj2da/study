# 01. 오프닝

## 지난번(Day 1) 내용 복습

- **데이터 엔지니어링**: 데이터 파이프라인(수집→저장→처리→분석)을 구축·관리하는 역할
- **빅데이터·분산 처리**: 3V(Volume, Velocity, Variety), 단일 서버 한계, 분산 시스템 필요성
- **Linux 기본 명령어**: `pwd`, `ls`, `cd`, `cp`, `mv`, `rm`, `mkdir`, `cat`, `head`, `tail`, `grep`, `find`
- **Docker/Podman**: 컨테이너로 동일한 실습 환경 구성

→ 오늘은 **분산 저장**을 배우므로, "데이터를 **어디에 어떻게** 둘지"가 Day1의 "파이프라인·분산이 왜 필요하냐"와 이어집니다.

---

## 오늘의 학습 목표

오늘 강의를 마치면:
1. 분산 파일 시스템의 필요성과 원리를 이해한다
2. HDFS의 구조와 동작 방식을 설명할 수 있다
3. Docker 네트워크를 생성하고 컨테이너 간 통신을 구성할 수 있다
4. HDFS에 데이터를 업로드하고 조회할 수 있다
5. 분산 저장의 장단점과 CAP 이론을 이해한다

---

## 📝 오늘의 진행 순서

1. [01_오프닝.md](01_오프닝.md) - 오프닝 및 Day1 복습 (지금 여기!)
2. [02_NFS_CIFS_개념.md](02_NFS_CIFS_개념.md) - NFS/CIFS 개념
3. [03_HDFS_개념_구조.md](03_HDFS_개념_구조.md) - HDFS 구조와 원리
4. [04_분산저장_아키텍처.md](04_분산저장_아키텍처.md) - 분산 저장 아키텍처 (CAP 이론)
5. [05_HDFS_환경구성.md](05_HDFS_환경구성.md) - HDFS 클러스터 구축
6. [06_HDFS_데이터_업로드.md](06_HDFS_데이터_업로드.md) - HDFS 데이터 업로드
7. [07_HDFS_데이터_조회_관리.md](07_HDFS_데이터_조회_관리.md) - HDFS 데이터 조회 및 관리
8. [08_분산저장_시나리오.md](08_분산저장_시나리오.md) - 분산 저장 시나리오
9. [09_QA_마무리.md](09_QA_마무리.md) - Q&A 및 마무리

---

## 중요 사항

### Day 3 연동 준비
Day3에서 Spark가 HDFS 데이터를 읽으므로:
- **`data-engineering-network` 생성 필수** (05번에서 진행)
- **HDFS 환경 유지** (Day2 종료 후에도 컨테이너 실행 상태 유지)
- **HDFS 데이터 확인** (`/user/data/sample_data.csv`)
