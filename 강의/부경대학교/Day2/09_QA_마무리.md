# 09. Q&A 및 마무리

## 오늘 배운 내용 요약

### 핵심 개념

1. **네트워크 스토리지**
   - NFS/CIFS: 중앙 집중식 스토리지의 개념과 한계
   - 단일 장애점(SPOF), 네트워크 병목 문제

2. **HDFS 아키텍처**
   - NameNode: 메타데이터 관리 (파일 위치, 블록 정보)
   - DataNode: 실제 데이터 블록 저장
   - 블록 단위 저장 (128MB), 복제 (기본 3개), Rack Awareness

3. **분산 저장 설계**
   - CAP 이론: Consistency, Availability, Partition Tolerance
   - HDFS 설계 철학: 한 번 쓰고 여러 번 읽기 (Write Once, Read Many)

4. **실습**
   - Docker/Podman Compose로 HDFS 클러스터 구성
   - `data-engineering-network` 생성 (Day3 Spark 연동 준비)
   - `hdfs dfs` 명령어: `-mkdir`, `-put`, `-get`, `-ls`, `-cat`, `-rm`
   - 로그 파일 분산 저장 시나리오

---

## Q&A

**자유 질문 시간** — 시간이 남으면 자유롭게 질문받습니다.

- 오늘 다룬 내용·실습·다음 날 준비뿐 아니라
- **네이버 회사 생활은 어떤지**
- **개발자로써 성장하려면 어떻게 해야 하는지**
- **회사 취업 꿀팁이 있는지**
- **오픈소스 메인테이너는 어떻게 됐는지**
- **해외 어디서 살았는지**

등등 편하게 질문 받습니다.

---

### 자주 나오는 질문 (FAQ)

**Q: HDFS vs S3/GCS 차이는?**  
A: **HDFS**는 온프레미스에서 직접 관리하며 낮은 지연시간이 장점입니다. **S3/GCS**는 클라우드 관리형 서비스로 높은 가용성과 관리 편의성이 장점입니다. 실무에서는 두 가지를 혼용하기도 합니다.

**Q: NameNode가 죽으면 어떻게 되나요?**  
A: HDFS 전체가 중단됩니다 (SPOF - Single Point of Failure). 실무에서는 **HA(High Availability)** 구성으로 Secondary NameNode를 두어 장애 대응합니다.

**Q: 블록 크기가 왜 128MB인가요?**  
A: 대용량 파일 처리에 최적화되어 있습니다. 메타데이터 오버헤드를 줄이고, 네트워크 전송 효율을 높이기 위해 큰 블록을 사용합니다.

**Q: 실습 중 DataNode 연결 문제가 생겼어요**  
A: NameNode가 완전히 시작되기 전에 DataNode가 연결 시도하면 발생합니다. `podman compose down` 후 다시 시작하거나, 1분 정도 기다려 보세요. 포트 8020이 제대로 열려 있는지도 확인하세요.

**Q: Day3 전에 뭘 해두면 좋을까요?**  
A: **HDFS 환경을 유지**해 두세요 (컨테이너 실행 상태). Day3에서 Spark가 HDFS 데이터를 읽습니다. (선택) Apache Spark가 무엇인지 미리 읽어보면 이해에 도움이 됩니다.

---

## 내일 준비사항

- **HDFS 환경 유지** (컨테이너 실행 상태 유지)
  - Day3에서 Spark가 HDFS 데이터를 읽습니다.
  - `data-engineering-network`가 생성되어 있어야 합니다.
- **(선택) Apache Spark 개념 미리 읽어 오기**
  - [AWS - Apache Spark란?](https://aws.amazon.com/ko/what-is/apache-spark/)
  - [IBM - Apache Spark란 무엇인가요?](https://www.ibm.com/kr-ko/think/topics/apache-spark)
  - 또는 스스로 검색하여 Spark 개념 파악

**확인 사항:**
```bash
# 네트워크 확인
podman network ls | grep data-engineering

# HDFS 컨테이너 확인
podman ps | grep namenode
podman ps | grep datanode

# HDFS 데이터 확인
podman exec -it namenode hdfs dfs -ls /user/data/
```

---

## 다음 시간 예고

**Day 3: 분산 처리 기초 (Apache Spark)**

HDFS에 저장한 데이터를 **Spark로 읽어서 분석**하고, 결과를 다시 HDFS에 저장하는 실습을 진행합니다.

- Spark 개념 및 아키텍처
- PySpark DataFrame API
- HDFS ↔ Spark 연동
- Spark SQL
- 종합 실습 과제

---

## 수고하셨습니다!

오늘 분산 스토리지의 기초를 배웠습니다. 내일은 분산 처리를 배워봅니다!
