# 04. 질문 정리 및 해소

## 학생들의 질문 수집

### 질문 카테고리

**1. 개념 이해**

- 이해가 안 되는 개념
- 헷갈리는 용어
- Day 1~4 복습 중 궁금한 점

**2. 실습 관련**

- 실습 중 막혔던 부분
- 에러 해결 방법
- 환경 설정 문제

**3. 실무 적용**

- 실무에서는 어떻게 사용하는지
- 취업 준비 방법
- 추가 학습 방향

---

## Q&A 세션

### 자주 나오는 질문 (FAQ)

#### Q1: "실무에서 정말 HDFS를 많이 쓰나요?"

**A**: 상황에 따라 다릅니다.

**온프레미스 환경**:

- HDFS를 많이 사용합니다.
- 특히 대용량 로그 데이터, 배치 처리에 적합합니다.

**클라우드 환경**:

- AWS S3, GCP Cloud Storage, Azure Blob Storage 등 **클라우드 스토리지**를 더 많이 사용합니다.
- HDFS 개념을 이해하면 클라우드 스토리지도 쉽게 이해할 수 있습니다.

**네이버 사례**:

- 자체 IDC에서 HDFS 사용 (Seamless HDFS)
- 클라우드 마이그레이션 중 (JuiceFS 등)

---

#### Q2: "Spark 말고 다른 처리 엔진도 배워야 하나요?"

**A**: 상황에 따라 선택합니다.

**Spark**:

- 가장 범용적이고 인기 있는 처리 엔진
- 배치, 스트리밍, SQL, ML 모두 가능
- **먼저 Spark를 마스터하는 것을 추천**

**다른 엔진들**:

- **Apache Flink**: 실시간 스트리밍에 강점 (Spark보다 낮은 지연 시간)
- **Apache Hive**: SQL 중심, 배치 처리 (Spark보다 느리지만 SQL 친화적)
- **Presto/Trino**: 대화형 쿼리, 빠른 응답 시간

**추천 학습 순서**:

1. Spark 마스터 (배치 + 스트리밍)
2. 필요에 따라 Flink (실시간) 또는 Presto (대화형 쿼리) 학습

---

#### Q3: "데이터 엔지니어 취업하려면 뭘 준비해야 하나요?"

**A**: 다음 3가지를 준비하세요.

**1. 기술 스택**

- **필수**: Python, SQL, Linux
- **중요**: Spark, Airflow, Docker
- **선택**: Kafka, Flink, 클라우드 (AWS/GCP/Azure)

**2. 프로젝트 경험**

- 개인 프로젝트: 공공 데이터 파이프라인 구축
- 오픈소스 기여: GitHub에서 데이터 엔지니어링 프로젝트 기여
- Kaggle: 데이터셋으로 실습

**3. 포트폴리오**

- GitHub: 코드 공개 (README 잘 작성)
- 블로그: 학습 내용 정리, 문제 해결 과정 공유
- LinkedIn: 프로필 작성, 네트워킹

**팁**:

- 자격증보다 **실전 경험**이 중요
- 면접에서 "어떤 문제를 해결했는지" 설명할 수 있어야 함

---

#### Q4: "Python vs Scala, 어떤 걸 배워야 하나요?"

**A**: **Python을 먼저 배우세요.**

**Python**:

- 배우기 쉬움
- 데이터 엔지니어링 + 데이터 사이언스 모두 사용
- PySpark, Airflow, dbt 등 대부분의 도구가 Python 지원

**Scala**:

- Spark의 네이티브 언어 (성능 최적화 가능)
- 하지만 **PySpark도 충분히 빠름**
- Scala는 필요할 때 배워도 늦지 않음

**추천**:

- Python 마스터 → 필요하면 Scala 학습

---

#### Q5: "클라우드 자격증 따야 하나요?"

**A**: **선택 사항**입니다.

**장점**:

- 클라우드 서비스 체계적으로 학습
- 이력서에 추가 가능

**단점**:

- 비용 (시험료 + 학습 자료)
- 자격증만으로는 취업 보장 안 됨

**추천**:

- 자격증보다 **실전 프로젝트**가 더 중요
- 클라우드 무료 티어로 실습하면서 학습
- 필요하면 AWS Certified Data Analytics, GCP Professional Data Engineer 등 고려

---

#### Q6: "실무에서 파이프라인 실패하면 어떻게 하나요?"

**A**: **모니터링·알림 시스템**이 필수입니다.

**실패 대응 프로세스**:

1. **알림 받기**: Airflow, Slack, 이메일 등
2. **로그 확인**: 어디서 실패했는지 파악
3. **원인 분석**: 데이터 문제? 코드 문제? 인프라 문제?
4. **재실행**: 멱등성이 있어야 안전하게 재실행 가능
5. **사후 조치**: 같은 문제 재발 방지 (코드 수정, 모니터링 강화)

**예방**:

- **데이터 품질 검증**: 입력 데이터 검증
- **테스트**: 단위 테스트, 통합 테스트
- **재시도 정책**: Airflow에서 자동 재시도 설정

---

## 추가 질문

**"다른 질문 있으신가요?"**

- 편하게 질문하세요!
- 실무 경험, 회사 생활, 취업 준비 등 무엇이든 괜찮습니다.

---

## 참고

- [05_결과물_검토_및_추가학습.md](05_결과물_검토_및_추가학습.md) — 다음 단계: 결과물 검토 및 추가 학습.

---

## 그림 출처

본 문서에는 별도 이미지가 사용되지 않았습니다.
