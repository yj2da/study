# 01. 오프닝

## 5일간의 여정 돌아보기

지난 4일 동안 우리는 다음을 배웠습니다:

### Day 1: 데이터 엔지니어링 & 빅데이터 기초

- 데이터 엔지니어링의 역할과 중요성
- Linux 기본 명령어
- Docker/Podman 환경 구성

### Day 2: 분산 시스템 & 스토리지

- 분산 파일 시스템의 필요성
- HDFS 아키텍처 (NameNode, DataNode)
- 블록 단위 저장과 복제

### Day 3: Spark & 분산 처리

- Apache Spark의 특징
- RDD, DataFrame
- Transformation vs Action
- PySpark 기본 연산

### Day 4: 데이터 처리 흐름 만들기

- 배치 처리와 파이프라인
- Data Warehouse vs Data Lake
- ETL/ELT/ETLT
- 파이프라인 자동화 및 검증

---

## 오늘의 학습 목표

**"배운 것을 모두 활용한 종합 실습"**

오늘 끝날 때, 여러분은 **완전한 데이터 파이프라인**을 구축하게 됩니다.

1. 4일간 배운 내용을 통합적으로 이해한다
2. 실제 데이터로 전체 파이프라인을 구축할 수 있다
3. 데이터 엔지니어링의 전체 흐름을 경험한다
4. 향후 학습 방향을 설정할 수 있다

---

## 📝 오늘의 진행 순서

1. [01_오프닝.md](01_오프닝.md) - 오프닝 및 5일 여정 돌아보기 (지금 여기!)
2. [02_Day1-4_복습.md](02_Day1-4_복습.md) - Day1~4 핵심 내용 리뷰
3. [03_종합실습.md](03_종합실습.md) - 전자상거래 로그 분석 파이프라인 구축
4. [04_질문_정리_및_해소.md](04_질문_정리_및_해소.md) - 질문 정리 및 해소
5. [05_결과물_검토_및_추가학습.md](05_결과물_검토_및_추가학습.md) - 결과물 검토 및 추가 학습
6. [06_마무리.md](06_마무리.md) - 마무리

---

## 마음가짐

- **완벽하지 않아도 괜찮습니다**: 4일 만에 모든 걸 마스터할 수 없습니다
- **과정이 중요합니다**: 오늘 실습을 통해 전체 흐름을 경험하는 것이 목표입니다
- **질문을 많이 하세요**: 마지막 날이니 궁금한 점을 모두 해소하세요
- **즐기세요**: 데이터 엔지니어링은 재미있는 분야입니다!

---

## 참고

- [02_Day1-4_복습.md](02_Day1-4_복습.md) — 다음 단계: Day1~4 핵심 내용 리뷰.

---

**"자, 그럼 시작해볼까요?"**
